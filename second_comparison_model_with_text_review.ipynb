{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PERTINENT_YEAR = 1960"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data and clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= pq.read_table('./data/wine_xwine_vivino.parquet').to_pandas()\n",
    "print(test.shape)\n",
    "\n",
    "#save to csv\n",
    "test[['WineID', 'Vintage', 'Review']].to_csv('./data/test_nb_review.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_ratings = pq.read_table('./data/all_wine_xwine_vivino.parquet').to_pandas()\n",
    "print(wine_ratings.shape)\n",
    "wine_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cast Vintage to int\n",
    "wine_ratings['Vintage'] = wine_ratings['Vintage'].astype(int)\n",
    "print(wine_ratings.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep only where CountRating >= 4 and Vintage >= 1960\n",
    "pertinent_wine_ratings = wine_ratings[wine_ratings['CountRating'] >=4]\n",
    "pertinent_wine_ratings = pertinent_wine_ratings[pertinent_wine_ratings['Vintage'] >= PERTINENT_YEAR]\n",
    "print(pertinent_wine_ratings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add weather features to the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add weather data to the dataframe by joining with ../weather_data/agg_monthly.parquet\n",
    "weather_data = pd.read_parquet('./data/agg_quarterly.parquet') \n",
    "\n",
    "# Take into account only the weather data from 1960\n",
    "weather_data = weather_data[weather_data['year'] >= PERTINENT_YEAR]\n",
    "\n",
    "# Take into account only columns: RegionID, year, avg_temperature, avg_sunshine_duration, avg_precipitation, avg_rain, avg_humidity, avg_soil_temperature, avg_soil_moisture\n",
    "weather_data = weather_data[['RegionID', 'year', 'quarter', 'avg_temperature', 'avg_sunshine_duration', 'avg_precipitation', 'avg_rain', 'avg_humidity', 'avg_soil_temperature', 'avg_soil_moisture']]\n",
    "# Create a new dataframe with the data for each region and year, and with a group of column for each quarter\n",
    "for index, row in weather_data.iterrows():\n",
    "    quarter = int(row['quarter'])\n",
    "    weather_data.at[index, f'avg_temperature_q{quarter}'] = row['avg_temperature']\n",
    "    weather_data.at[index, f'avg_sunshine_duration_q{quarter}'] = row['avg_sunshine_duration']\n",
    "    weather_data.at[index, f'avg_precipitation_q{quarter}'] = row['avg_precipitation']\n",
    "    weather_data.at[index, f'avg_rain_q{quarter}'] = row['avg_rain']\n",
    "    weather_data.at[index, f'avg_humidity_q{quarter}'] = row['avg_humidity']\n",
    "    weather_data.at[index, f'avg_soil_temperature_q{quarter}'] = row['avg_soil_temperature']\n",
    "    weather_data.at[index, f'avg_soil_moisture_q{quarter}'] = row['avg_soil_moisture']\n",
    "    \n",
    "# Drop the columns that are not needed anymore\n",
    "weather_data = weather_data.drop(['quarter', 'avg_temperature', 'avg_sunshine_duration', 'avg_precipitation', 'avg_rain', 'avg_humidity', 'avg_soil_temperature', 'avg_soil_moisture'], axis=1)\n",
    "\n",
    "# Group the data by RegionID and year and take the max of each column\n",
    "weather_data = weather_data.groupby(['RegionID', 'year']).max().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the column RegionID to Region\n",
    "weather_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(weather_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Join the weather data with the pertinent_wine_ratings dataframe\n",
    "pertinent_wine_ratings_with_weather = pertinent_wine_ratings.merge(weather_data, left_on=['RegionID', 'Vintage'], right_on=['RegionID', 'year'])\n",
    "# Drop the column year\n",
    "pertinent_wine_ratings_with_weather = pertinent_wine_ratings_with_weather.drop(['year'], axis=1)\n",
    "\n",
    "print(pertinent_wine_ratings_with_weather.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pertinent_wine_ratings_with_weather.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and train a doc2vec model on the colume 'review'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop null values in review column\n",
    "pertinent_ratings_non_null = pertinent_wine_ratings.dropna(subset=['Review'])\n",
    "print(pertinent_ratings_non_null.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pertinent_ratings_non_null['Review']\n",
    "unique_reviews = reviews.unique()\n",
    "\n",
    "#convert to pandas series\n",
    "unique_reviews = pd.Series(unique_reviews)\n",
    "print(len(unique_reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english')) | set(stopwords.words('french')) | set(stopwords.words('spanish'))\n",
    "import string\n",
    "\n",
    "def clean_review_for_doc2vec(review):\n",
    "    #Clean the unique reviews series with lower case and remove punctuation\n",
    "    review = review.lower()\n",
    "    review = review.translate(str.maketrans('', '', string.punctuation))\n",
    "    #Remove stop words in each review\n",
    "    review = review.split()\n",
    "    review = [word for word in review if not word in stop_words]\n",
    "    review = ' '.join(review)\n",
    "    #remove emojis in each review\n",
    "    review = review.encode('ascii', 'ignore').decode('ascii')\n",
    "    return review\n",
    "\n",
    "unique_reviews_no_punctuation_no_stop_word = unique_reviews.apply(clean_review_for_doc2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(unique_reviews[1])\n",
    "print(unique_reviews_no_punctuation_no_stop_word[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the longest review in unique_reviews\n",
    "max_len = 0\n",
    "for x in unique_reviews_no_punctuation_no_stop_word:\n",
    "    if len(x.split()) > max_len:\n",
    "        max_len = len(x.split())\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec,TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# preproces the documents, and create TaggedDocuments\n",
    "tagged_data = [TaggedDocument(words=word_tokenize(doc.lower()),\n",
    "                              tags=[str(i)]) for i,\n",
    "               doc in enumerate(unique_reviews_no_punctuation_no_stop_word)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the Doc2vec model\n",
    "model = Doc2Vec(vector_size=100,\n",
    "                min_count=5, epochs=50)\n",
    "model.build_vocab(tagged_data)\n",
    "model.train(tagged_data,\n",
    "            total_examples=model.corpus_count,\n",
    "            epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "model.save(\"./data/doc2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "model= Doc2Vec.load(\"./data/doc2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_reviews = reviews.apply(clean_review_for_doc2vec)\n",
    "print(len(cleaned_reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the document vectors\n",
    "document_vectors = [model.infer_vector(\n",
    "    word_tokenize(doc)) for doc in cleaned_reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert document vectors to dataframe\n",
    "document_vectors_df = pd.DataFrame(document_vectors, columns=['doc2vec'+str(i) for i in range(len(document_vectors[0]))])\n",
    "print(document_vectors_df.shape)\n",
    "\n",
    "#find the min of each column\n",
    "print(min(document_vectors_df.min()))\n",
    "print(max(document_vectors_df.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the wineID and review columns from pertinent_wine_ratings\n",
    "key = pertinent_ratings_non_null[['WineID', 'Vintage']]\n",
    "print(key.shape)\n",
    "#concatenate key and document_vectors_df vertically\n",
    "wine_with_only_text_review = pd.concat([key.reset_index(drop=True),document_vectors_df.reset_index(drop=True)], axis=1)\n",
    "print(wine_with_only_text_review.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggregate the document vectors by wineID and vintage -> average\n",
    "aggregated_doc_vector = wine_with_only_text_review.groupby(['WineID', 'Vintage']).mean().reset_index()\n",
    "\n",
    "aggregated_doc_vector.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(451, 102)\n"
     ]
    }
   ],
   "source": [
    "print(aggregated_doc_vector.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's separate the data that can be calculate with a distance from the others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_normalize = pertinent_wine_ratings_with_weather.drop(['RegionID', 'MinRating', 'MaxRating','Type','CountRating', 'Review'], axis=1)\n",
    "data_to_normalize.dropna(inplace=True)\n",
    "data_to_normalize.drop_duplicates(inplace=True)\n",
    "print(data_to_normalize.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_to_normalize.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the dictionary for the categorical variables\n",
    "\n",
    "acid = data_to_normalize['Acidity'].unique()\n",
    "print(acid)\n",
    "\n",
    "body = data_to_normalize['Body'].unique()\n",
    "print(body)\n",
    "\n",
    "elaborate = data_to_normalize['Elaborate'].unique()\n",
    "print(elaborate)\n",
    "\n",
    "acid_dict = {'Low': 1, 'Medium': 2, 'High': 3}\n",
    "body_dict = {'Very light-bodied': 1, 'Light-bodied': 2, 'Medium-bodied': 3, 'Full-bodied': 4, 'Very full-bodied': 5}\n",
    "elaborat_dict = {'Varietal/100%':1, 'Varietal/>75%': 2, 'Assemblage/Blend' : 3,\n",
    "                 'Assemblage/Meritage Red Blend':4, 'Assemblage/Meritage White Blend': 5, \n",
    "                 'Assemblage/Rhône Red Blend':6, 'Assemblage/Bordeaux Red Blend':7 , \n",
    "                 'Assemblage/Bourgogne Red Blend': 8, 'Assemblage/Bourgogne White Blend': 9, 'Assemblage/Portuguese White Blend': 10, \n",
    "                 'Assemblage/Portuguese Red Blend': 11, 'Assemblage/Port Blend': 12,  \n",
    "                 'Assemblage/Provence Rosé Blend' :13, 'Assemblage/Champagne Blend': 14, 'Assemblage/Valpolicella Red Blend': 15,\n",
    "                 'Assemblage/Chianti Red Blend': 16, 'Assemblage/Tuscan Red Blend': 17, 'Assemblage/Rioja Red Blend': 18, \n",
    "                 'Assemblage/Rioja White Blend' : 19, 'Assemblage/Priorat Red Blend': 20,\n",
    "                 'Assemblage/Cava Blend': 21, 'Assemblage/Soave White Blend': 22\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Label Encoding\n",
    "data_to_normalize['Body'] = data_to_normalize['Body'].map(body_dict)\n",
    "data_to_normalize['Acidity'] = data_to_normalize['Acidity'].map(acid_dict)\n",
    "data_to_normalize['Elaborate'] = data_to_normalize['Elaborate'].map(elaborat_dict)\n",
    "\n",
    "data_to_normalize.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count null values\n",
    "data_to_normalize.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The wine_dataset must contain the following columns: ['WineID','Vintage', 'WineName']. \n",
    "# The other columns are the features.\n",
    "def normalize_wine_data(wine_dataset):\n",
    "    ## Select Features and Target\n",
    "    features = wine_dataset.drop(['WineID','Vintage', 'WineName'], axis=1)\n",
    "    targets = wine_dataset[['WineID','Vintage', 'WineName']]\n",
    "    ## Normalize Features\n",
    "    for column in features.columns:\n",
    "        features[column] = (features[column] - features[column].min()) / (features[column].max() - features[column].min())\n",
    "    ## Return normalized dataset\n",
    "    normalized_df = pd.concat([targets.reset_index(drop=True),features.reset_index(drop=True)], axis=1)\n",
    "    return normalized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(580596, 37)\n"
     ]
    }
   ],
   "source": [
    "# Normalize the data\n",
    "normalized_wine_data = normalize_wine_data(data_to_normalize)\n",
    "print(normalized_wine_data.shape)\n",
    "print(normalized_wine_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's add Doc2Vec vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_text_review_vec = aggregated_doc_vector.copy()\n",
    "wine_name_data = pertinent_wine_ratings[['WineID', 'Vintage', 'WineName']].drop_duplicates()\n",
    "wine_text_review_vec = wine_text_review_vec.merge(wine_name_data, left_on=['WineID', 'Vintage'], right_on=['WineID', 'Vintage'])\n",
    "\n",
    "#move column WineName to the third column\n",
    "wine_text_review_vec = wine_text_review_vec[['WineID', 'Vintage', 'WineName'] + [col for col in wine_text_review_vec.columns if col not in ['WineID', 'Vintage', 'WineName']]]\n",
    "\n",
    "print(wine_text_review_vec.shape)\n",
    "print(wine_text_review_vec.head()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now, let's compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_id = 102356\n",
    "vintage = 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ((wine_text_review_vec['WineID'] == wine_id) & (wine_text_review_vec['Vintage'] == vintage)).any():\n",
    "    print(\"Wine ID found\")\n",
    "else:\n",
    "    print(\"Wine ID not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ((normalized_wine_data['WineID'] == wine_id) & (normalized_wine_data['Vintage'] == vintage)).any():\n",
    "    print(\"Wine ID found\")\n",
    "else:\n",
    "    print(\"Wine ID not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_found_dict = {\"Wine ID found with text review\" : 0,\n",
    "                \"Wine ID found without text review\" : 1,\n",
    "                \"Wine ID not found\" : 2\n",
    "                }\n",
    "wine_found = \"Wine ID not found\"\n",
    "\n",
    "if ((normalized_wine_data['WineID'] == wine_id) & (normalized_wine_data['Vintage'] == vintage)).any():\n",
    "    reference_wine_composition_and_weather = normalized_wine_data.loc[(normalized_wine_data['WineID'] == wine_id) & (normalized_wine_data['Vintage'] == vintage)] \n",
    "    \n",
    "    if ((wine_text_review_vec['WineID'] == wine_id) & (wine_text_review_vec['Vintage'] == vintage)).any():\n",
    "        wine_found = \"Wine ID found with text review\"\n",
    "        \n",
    "        #find row with index wine_id and vintage_id in pertinent_ratings\n",
    "        reference_wine_text_review = wine_text_review_vec.loc[(wine_text_review_vec['WineID'] == wine_id) & (wine_text_review_vec['Vintage'] == vintage)]\n",
    "        #print(reference_wine_text_review)\n",
    "    else:\n",
    "        wine_found = \"Wine ID found without text review\"\n",
    "\n",
    "print(wine_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(reference_wine_composition_and_weather)\n",
    "list = reference_wine_composition_and_weather.values.tolist()\n",
    "print(list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "def get_distance_for_composition_and_weather(row):    \n",
    "    row_to_list = row.values.tolist()\n",
    "    row_composition_np_array = np.array(row_to_list[3:8])\n",
    "    row_weather_np_array = np.array(row_to_list[8:])\n",
    "\n",
    "    reference_wine_characteristic_list = reference_wine_composition_and_weather.values.tolist()\n",
    "    reference_composition_np_array = np.array(reference_wine_characteristic_list[0][3:8])\n",
    "    reference_weather_np_array = np.array(reference_wine_characteristic_list[0][8:])\n",
    "   \n",
    "    return distance.euclidean(row_composition_np_array, reference_composition_np_array) + distance.euclidean(row_weather_np_array, reference_weather_np_array)\n",
    "\n",
    "def get_distance_for_text_review(row):\n",
    "    doc_vector_for_row = wine_text_review_vec.loc[(aggregated_doc_vector['WineID'] == row['WineID']) & (aggregated_doc_vector['Vintage'] == row['Vintage'])].iloc[0]\n",
    "    doc_vector_for_row_list = doc_vector_for_row.values.tolist()\n",
    "    doc_vector_for_row_np_array = np.array(doc_vector_for_row_list[3:])\n",
    "\n",
    "    reference_wine_text_review_list = reference_wine_text_review.values.tolist()\n",
    "    reference_wine_text_review_np_array = np.array(reference_wine_text_review_list[0][3:])\n",
    "\n",
    "    return distance.euclidean(doc_vector_for_row_np_array, reference_wine_text_review_np_array)\n",
    "\n",
    "def get_distance_for_composition_and_weather_and_text_review(row):\n",
    "    composition_and_weather_distance = get_distance_for_composition_and_weather(row)\n",
    "    \n",
    "    if (wine_found_dict[wine_found] == 0):\n",
    "        if ((wine_text_review_vec['WineID'] == row['WineID']) & (wine_text_review_vec['Vintage'] == row['Vintage'])).any():\n",
    "            return 0.67*composition_and_weather_distance + 0.33*get_distance_for_text_review(row)\n",
    "    return composition_and_weather_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1_composition_and_weather = normalized_wine_data.loc[(normalized_wine_data['WineID'] == 106708) & (normalized_wine_data['Vintage'] == 2005)].iloc[0]\n",
    "test1_composition_and_weather_list = test1_composition_and_weather.values.tolist()\n",
    "print(test1_composition_and_weather_list)\n",
    "print(reference_wine_composition_and_weather.values.tolist())\n",
    "\n",
    "print(get_distance_for_composition_and_weather(test1_composition_and_weather))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1_composition_and_weather_text_review = wine_text_review_vec.loc[(wine_text_review_vec['WineID'] == 106708) & (wine_text_review_vec['Vintage'] == 2005)].iloc[0]\n",
    "test1_composition_and_weather_text_review_list = test1_composition_and_weather_text_review.values.tolist()\n",
    "print(test1_composition_and_weather_text_review_list)\n",
    "print(reference_wine_text_review.values.tolist())\n",
    "\n",
    "print(get_distance_for_text_review(test1_composition_and_weather_text_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_wine_data['distance'] = normalized_wine_data.apply(get_distance_for_composition_and_weather_and_text_review, axis=1)\n",
    "print(normalized_wine_data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(normalized_wine_data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reference wine is Douro Quinta da Manoella VV Tinto in year 2018\n",
      "The 10 most similar wines are:\n",
      "Douro Quinta da Manoella VV Tinto in year 2018 with distance 0.0\n",
      "Vinhas Velhas Limited Release Touriga Nacional in year 2018 with distance 0.0\n",
      "Douro in year 2018 with distance 0.0029761904761904656\n",
      "Reserva Vinhas Velhas in year 2018 with distance 0.004999999999999893\n",
      "Touriga Nacional Reserva in year 2018 with distance 0.011904761904761862\n",
      "Reserva in year 2018 with distance 0.014731391274719766\n",
      "Douro Reserva Red in year 2018 with distance 0.015625\n",
      "Guyot Tinto in year 2018 with distance 0.017857142857142794\n",
      "Syrah in year 2018 with distance 0.017857142857142794\n",
      "Reserva Touriga Nacional in year 2018 with distance 0.01877891289304159\n",
      "Altitude in year 2018 with distance 0.01877891289304159\n"
     ]
    }
   ],
   "source": [
    "# Sort the DataFrame by the euclidean_distance column and display the 10 nearest wines\n",
    "ref_wine_name = normalized_wine_data.loc[(normalized_wine_data['WineID'] == wine_id) & (normalized_wine_data['Vintage'] == vintage)]['WineName'].values[0]\n",
    "print(\"reference wine is \"+ ref_wine_name + \" in year \" + str(vintage))\n",
    "print(\"The 10 most similar wines are:\")\n",
    "\n",
    "sorted_df = normalized_wine_data.sort_values(by=['distance'])\n",
    "top_10 = sorted_df.head(11)\n",
    "\n",
    "for index, row in top_10.iterrows():\n",
    "    print(row['WineName'] + \" in year \" + str(row['Vintage']) + \" with distance \" + str(row['distance']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
