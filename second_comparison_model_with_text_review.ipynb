{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PERTINENT_YEAR = 1960"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data and clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= pq.read_table('./data/wine_xwine_vivino.parquet').to_pandas()\n",
    "print(test.shape)\n",
    "\n",
    "#save to csv\n",
    "test[['WineID', 'Vintage', 'Review']].to_csv('./data/test_nb_review.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_ratings = pq.read_table('./data/all_wine_xwine_vivino.parquet').to_pandas()\n",
    "print(wine_ratings.shape)\n",
    "wine_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cast Vintage to int\n",
    "wine_ratings['Vintage'] = wine_ratings['Vintage'].astype(int)\n",
    "print(wine_ratings.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep only where CountRating >= 4 and Vintage >= 1960\n",
    "pertinent_wine_ratings = wine_ratings[wine_ratings['CountRating'] >=4]\n",
    "pertinent_wine_ratings = pertinent_wine_ratings[pertinent_wine_ratings['Vintage'] >= PERTINENT_YEAR]\n",
    "print(pertinent_wine_ratings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add weather features to the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add weather data to the dataframe by joining with ../weather_data/agg_monthly.parquet\n",
    "weather_data = pd.read_parquet('./data/agg_quarterly.parquet') \n",
    "\n",
    "# Take into account only the weather data from 1960\n",
    "weather_data = weather_data[weather_data['year'] >= PERTINENT_YEAR]\n",
    "\n",
    "# Take into account only columns: RegionID, year, avg_temperature, avg_sunshine_duration, avg_precipitation, avg_rain, avg_humidity, avg_soil_temperature, avg_soil_moisture\n",
    "weather_data = weather_data[['RegionID', 'year', 'quarter', 'avg_temperature', 'avg_sunshine_duration', 'avg_precipitation', 'avg_rain', 'avg_humidity', 'avg_soil_temperature', 'avg_soil_moisture']]\n",
    "# Create a new dataframe with the data for each region and year, and with a group of column for each quarter\n",
    "for index, row in weather_data.iterrows():\n",
    "    quarter = int(row['quarter'])\n",
    "    weather_data.at[index, f'avg_temperature_q{quarter}'] = row['avg_temperature']\n",
    "    weather_data.at[index, f'avg_sunshine_duration_q{quarter}'] = row['avg_sunshine_duration']\n",
    "    weather_data.at[index, f'avg_precipitation_q{quarter}'] = row['avg_precipitation']\n",
    "    weather_data.at[index, f'avg_rain_q{quarter}'] = row['avg_rain']\n",
    "    weather_data.at[index, f'avg_humidity_q{quarter}'] = row['avg_humidity']\n",
    "    weather_data.at[index, f'avg_soil_temperature_q{quarter}'] = row['avg_soil_temperature']\n",
    "    weather_data.at[index, f'avg_soil_moisture_q{quarter}'] = row['avg_soil_moisture']\n",
    "    \n",
    "# Drop the columns that are not needed anymore\n",
    "weather_data = weather_data.drop(['quarter', 'avg_temperature', 'avg_sunshine_duration', 'avg_precipitation', 'avg_rain', 'avg_humidity', 'avg_soil_temperature', 'avg_soil_moisture'], axis=1)\n",
    "\n",
    "# Group the data by RegionID and year and take the max of each column\n",
    "weather_data = weather_data.groupby(['RegionID', 'year']).max().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the column RegionID to Region\n",
    "weather_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(weather_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Join the weather data with the pertinent_wine_ratings dataframe\n",
    "pertinent_wine_ratings_with_weather = pertinent_wine_ratings.merge(weather_data, left_on=['RegionID', 'Vintage'], right_on=['RegionID', 'year'])\n",
    "# Drop the column year\n",
    "pertinent_wine_ratings_with_weather = pertinent_wine_ratings_with_weather.drop(['year'], axis=1)\n",
    "\n",
    "print(pertinent_wine_ratings_with_weather.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pertinent_wine_ratings_with_weather.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and train a doc2vec model on the colume 'review'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop null values in review column\n",
    "pertinent_ratings_non_null = pertinent_wine_ratings.dropna(subset=['Review'])\n",
    "print(pertinent_ratings_non_null.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pertinent_ratings_non_null['Review']\n",
    "unique_reviews = reviews.unique()\n",
    "\n",
    "#convert to pandas series\n",
    "unique_reviews = pd.Series(unique_reviews)\n",
    "print(len(unique_reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english')) | set(stopwords.words('french')) | set(stopwords.words('spanish'))\n",
    "import string\n",
    "\n",
    "def clean_review_for_doc2vec(review):\n",
    "    #Clean the unique reviews series with lower case and remove punctuation\n",
    "    review = review.lower()\n",
    "    review = review.translate(str.maketrans('', '', string.punctuation))\n",
    "    #Remove stop words in each review\n",
    "    review = review.split()\n",
    "    review = [word for word in review if not word in stop_words]\n",
    "    review = ' '.join(review)\n",
    "    #remove emojis in each review\n",
    "    review = review.encode('ascii', 'ignore').decode('ascii')\n",
    "    return review\n",
    "\n",
    "unique_reviews_no_punctuation_no_stop_word = unique_reviews.apply(clean_review_for_doc2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(unique_reviews[1])\n",
    "print(unique_reviews_no_punctuation_no_stop_word[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the longest review in unique_reviews\n",
    "max_len = 0\n",
    "for x in unique_reviews_no_punctuation_no_stop_word:\n",
    "    if len(x.split()) > max_len:\n",
    "        max_len = len(x.split())\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec,TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# preproces the documents, and create TaggedDocuments\n",
    "tagged_data = [TaggedDocument(words=word_tokenize(doc.lower()),\n",
    "                              tags=[str(i)]) for i,\n",
    "               doc in enumerate(unique_reviews_no_punctuation_no_stop_word)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the Doc2vec model\n",
    "model = Doc2Vec(vector_size=100,\n",
    "                min_count=5, epochs=50)\n",
    "model.build_vocab(tagged_data)\n",
    "model.train(tagged_data,\n",
    "            total_examples=model.corpus_count,\n",
    "            epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "model.save(\"./data/doc2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "model= Doc2Vec.load(\"./data/doc2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_reviews = reviews.apply(clean_review_for_doc2vec)\n",
    "print(len(cleaned_reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the document vectors\n",
    "document_vectors = [model.infer_vector(\n",
    "    word_tokenize(doc)) for doc in cleaned_reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert document vectors to dataframe\n",
    "document_vectors_df = pd.DataFrame(document_vectors, columns=['doc2vec'+str(i) for i in range(len(document_vectors[0]))])\n",
    "print(document_vectors_df.shape)\n",
    "\n",
    "#find the min of each column\n",
    "print(min(document_vectors_df.min()))\n",
    "print(max(document_vectors_df.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the wineID and review columns from pertinent_wine_ratings\n",
    "key = pertinent_ratings_non_null[['WineID', 'Vintage']]\n",
    "print(key.shape)\n",
    "#concatenate key and document_vectors_df vertically\n",
    "wine_with_only_text_review = pd.concat([key.reset_index(drop=True),document_vectors_df.reset_index(drop=True)], axis=1)\n",
    "print(wine_with_only_text_review.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggregate the document vectors by wineID and vintage -> average\n",
    "aggregated_doc_vector = wine_with_only_text_review.groupby(['WineID', 'Vintage']).mean().reset_index()\n",
    "\n",
    "aggregated_doc_vector.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(aggregated_doc_vector.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's separate the data that can be calculate with a distance from the others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_normalize = pertinent_wine_ratings_with_weather.drop(['RegionID', 'MinRating', 'MaxRating','Type','CountRating', 'Review'], axis=1)\n",
    "data_to_normalize.dropna(inplace=True)\n",
    "data_to_normalize.drop_duplicates(inplace=True)\n",
    "print(data_to_normalize.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_to_normalize.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the dictionary for the categorical variables\n",
    "\n",
    "acid = data_to_normalize['Acidity'].unique()\n",
    "print(acid)\n",
    "\n",
    "body = data_to_normalize['Body'].unique()\n",
    "print(body)\n",
    "\n",
    "elaborate = data_to_normalize['Elaborate'].unique()\n",
    "print(elaborate)\n",
    "\n",
    "acid_dict = {'Low': 1, 'Medium': 2, 'High': 3}\n",
    "body_dict = {'Very light-bodied': 1, 'Light-bodied': 2, 'Medium-bodied': 3, 'Full-bodied': 4, 'Very full-bodied': 5}\n",
    "elaborat_dict = {'Varietal/100%':1, 'Varietal/>75%': 2, 'Assemblage/Blend' : 3,\n",
    "                 'Assemblage/Meritage Red Blend':4, 'Assemblage/Meritage White Blend': 5, \n",
    "                 'Assemblage/Rhône Red Blend':6, 'Assemblage/Bordeaux Red Blend':7 , \n",
    "                 'Assemblage/Bourgogne Red Blend': 8, 'Assemblage/Bourgogne White Blend': 9, 'Assemblage/Portuguese White Blend': 10, \n",
    "                 'Assemblage/Portuguese Red Blend': 11, 'Assemblage/Port Blend': 12,  \n",
    "                 'Assemblage/Provence Rosé Blend' :13, 'Assemblage/Champagne Blend': 14, 'Assemblage/Valpolicella Red Blend': 15,\n",
    "                 'Assemblage/Chianti Red Blend': 16, 'Assemblage/Tuscan Red Blend': 17, 'Assemblage/Rioja Red Blend': 18, \n",
    "                 'Assemblage/Rioja White Blend' : 19, 'Assemblage/Priorat Red Blend': 20,\n",
    "                 'Assemblage/Cava Blend': 21, 'Assemblage/Soave White Blend': 22\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Label Encoding\n",
    "data_to_normalize['Body'] = data_to_normalize['Body'].map(body_dict)\n",
    "data_to_normalize['Acidity'] = data_to_normalize['Acidity'].map(acid_dict)\n",
    "data_to_normalize['Elaborate'] = data_to_normalize['Elaborate'].map(elaborat_dict)\n",
    "\n",
    "data_to_normalize.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The wine_dataset must contain the following columns: ['WineID','Vintage', 'WineName']. \n",
    "# The other columns are the features.\n",
    "def normalize_wine_data(wine_dataset):\n",
    "    ## Select Features and Target\n",
    "    features = wine_dataset.drop(['WineID','Vintage', 'WineName'], axis=1)\n",
    "    targets = wine_dataset[['WineID','Vintage', 'WineName']]\n",
    "    ## Normalize Features\n",
    "    for column in features.columns:\n",
    "        features[column] = (features[column] - features[column].min()) / (features[column].max() - features[column].min())\n",
    "    ## Return normalized dataset\n",
    "    normalized_df = pd.concat([targets.reset_index(drop=True),features.reset_index(drop=True)], axis=1)\n",
    "    return normalized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "normalized_wine_data = normalize_wine_data(data_to_normalize)\n",
    "print(normalized_wine_data.shape)\n",
    "print(normalized_wine_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(580596, 33)\n"
     ]
    }
   ],
   "source": [
    "normalized_wine_name_data = normalized_wine_data[['WineID', 'Vintage', 'WineName']]\n",
    "normalized_wine_calculate_data = normalized_wine_data.drop(['WineID', 'Vintage', 'WineName'], axis=1)\n",
    "print(normalized_wine_calculate_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's add Doc2Vec vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(451, 100)\n"
     ]
    }
   ],
   "source": [
    "wine_text_review_vec = aggregated_doc_vector.copy()\n",
    "wine_name_data = wine_text_review_vec[['WineID', 'Vintage']]\n",
    "wine_vec = wine_text_review_vec.drop(['WineID', 'Vintage'], axis=1)\n",
    "\n",
    "print(wine_vec.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now, let's compare using KD Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_id = 102356\n",
    "vintage = 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ((normalized_wine_data['WineID'] == wine_id) & (normalized_wine_data['Vintage'] == vintage)).any():\n",
    "    reference_wine_composition_and_weather = normalized_wine_data.loc[(normalized_wine_data['WineID'] == wine_id) & (normalized_wine_data['Vintage'] == vintage)] \n",
    "    if ((wine_text_review_vec['WineID'] == wine_id) & (wine_text_review_vec['Vintage'] == vintage)).any():\n",
    "        print(\"Wine ID found\")\n",
    "        reference_wine_text_review = wine_text_review_vec.loc[(wine_text_review_vec['WineID'] == wine_id) & (wine_text_review_vec['Vintage'] == vintage)]\n",
    "    else:\n",
    "        print(\"Wine ID found with no text review\")\n",
    "else:\n",
    "    print(\"Wine ID not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_wine_composition_and_weather = reference_wine_composition_and_weather.drop(['WineID','Vintage', 'WineName'], axis=1).to_numpy().reshape(1,-1)\n",
    "print(input_wine_composition_and_weather)\n",
    "\n",
    "input_wine_text_review = reference_wine_text_review.drop(['WineID','Vintage'], axis=1).to_numpy().reshape(1,-1)\n",
    "print(input_wine_text_review.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KDTree\n",
    "# Build the KD Tree\n",
    "wine_composition_weather_tree = KDTree(normalized_wine_calculate_data, metric='euclidean')\n",
    "wine_text_review_tree = KDTree(wine_vec, metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the KD Tree\n",
    "dist_composition_weather, ind_composition_weather = wine_composition_weather_tree.query(input_wine_composition_and_weather, k=len(normalized_wine_calculate_data))\n",
    "dist_text_review, ind_text_review = wine_text_review_tree.query(input_wine_text_review, k=len(wine_vec))\n",
    "\n",
    "# Print the results\n",
    "print(dist_composition_weather.shape)\n",
    "print(ind_composition_weather)\n",
    "print(dist_text_review.shape)\n",
    "print(ind_text_review.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary with ind as key and dist as value\n",
    "dict_composition_weather_wine = dict(zip(ind_composition_weather[0], dist_composition_weather[0]))\n",
    "print(dict_composition_weather_wine[53405])\n",
    "\n",
    "dict_text_review_wine = dict(zip(ind_text_review[0], dist_text_review[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dictionary with normalized_wine_data with the value of the key is the index of the row in normalized_wine_data\n",
    "# and the value is the distance\n",
    "normalized_wine_name_data['distance1'] = normalized_wine_data.index.map(dict_composition_weather_wine)\n",
    "print(normalized_wine_name_data.head())\n",
    "\n",
    "# find max of distance1\n",
    "max_distance1 = normalized_wine_name_data['distance1'].max()\n",
    "print(max_distance1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_name_data['distance2'] = wine_text_review_vec.index.map(dict_text_review_wine)\n",
    "print(wine_name_data.head())\n",
    "\n",
    "# find max of distance2\n",
    "max_distance2 = wine_name_data['distance2'].max()\n",
    "print(max_distance2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the datasets based on 'Name' and 'Age'\n",
    "merged_wine_data = pd.merge(normalized_wine_name_data, wine_name_data, on=['WineID', 'Vintage'],how='left')\n",
    "\n",
    "# Fill null values with 0 before adding 'ScoreDay1' and 'ScoreDay2'\n",
    "merged_wine_data['distance'] = merged_wine_data['distance1'].fillna(0) + merged_wine_data['distance2'].fillna(0)\n",
    "\n",
    "# Drop the redundant 'ScoreDay1' and 'ScoreDay2' columns if needed\n",
    "merged_wine_data = merged_wine_data.drop(['distance1', 'distance2'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_wine_data.shape)\n",
    "print(merged_wine_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reference wine is Douro Quinta da Manoella VV Tinto in year 2016\n",
      "The 10 most similar wines are:\n",
      "Vinhas Velhas Limited Release Touriga Nacional in year 2018 with distance 0.0\n",
      "Douro Quinta da Manoella VV Tinto in year 2018 with distance 0.0\n",
      "Douro in year 2018 with distance 0.0029761904761904656\n",
      "Reserva Vinhas Velhas in year 2018 with distance 0.004999999999999893\n",
      "Touriga Nacional Reserva in year 2018 with distance 0.011904761904761862\n",
      "Reserva in year 2018 with distance 0.014731391274719766\n",
      "Douro Reserva Red in year 2018 with distance 0.015625\n",
      "Guyot Tinto in year 2018 with distance 0.017857142857142794\n",
      "Syrah in year 2018 with distance 0.017857142857142794\n",
      "Altitude in year 2018 with distance 0.01877891289304159\n",
      "Reserva Touriga Nacional in year 2018 with distance 0.01877891289304159\n"
     ]
    }
   ],
   "source": [
    "# Sort the DataFrame by the euclidean_distance column and display the 10 nearest wines\n",
    "ref_wine_name = normalized_wine_data.loc[(normalized_wine_data['WineID'] == wine_id) & (normalized_wine_data['Vintage'] == vintage)]['WineName'].values[0]\n",
    "print(\"reference wine is \"+ ref_wine_name + \" in year \" + str(vintage))\n",
    "print(\"The 10 most similar wines are:\")\n",
    "\n",
    "sorted_df = merged_wine_data.sort_values(by=['distance'])\n",
    "top_10 = sorted_df.head(11)\n",
    "\n",
    "for index, row in top_10.iterrows():\n",
    "    print(row['WineName'] + \" in year \" + str(row['Vintage']) + \" with distance \" + str(row['distance']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
